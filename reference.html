<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CreaBots | Reference</title>
    <link rel="stylesheet" href="style.css">
    <style>

    </style>
</head>

<body>
    <nav class="navbar" style="background-image: url('images/bg.gif');">
        <a href="index.html"><img class="logo" src="images/logo.png" alt="Creabots Logo" /></a>
        <div class="nav-links" id="navLinks">
            <i class="fa fa-times" onclick="hideMenu()" aria-hidden="true"></i>
            <ul>
                <li><a href="index.html">HOME</a></li>
                <li><a href="index.html#demo">DEMO</a></li>
                <li><a href="approach.html">APPROACH</a></li>
                <li><a href="media.html">ASSETS</a></li>
                <li><a href="model.html">MODELS</a></li>
                <li><a href="index.html#team">TEAM</a></li>
            </ul>
        </div>

        <i class="fa fa-bars" onclick="showMenu()" aria-hidden="true"></i>
    </nav>

    <!----Reference------->
    <section class="approach">
        <h1 id="approach">Reference List</h1>
        <div class="container-block container">
            <div class="responsive-container-block teamcard-container">
                <div class="list approach-col">
                    <div class="num">
                        <h3>E. Şahin, M. Çakmak, M. R. Dog ̆ar, E. Ug ̆ur, and G. Üçoluk, “To afford or not to afford:
                            A new formalization of affordances toward affordance-based robot control,” Adaptive
                            Behavior, vol. 15, no. 4, 2007.</h3>
                    </div>
                    <div class="num">
                        <h3>A. Nguyen, D. Kanoulas, D. G. Caldwell, and N. G. Tsagarakis, “Object-based affordances
                            detection with convolutional neural networks and dense conditional random fields,” in 2017
                            IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2017.</h3>
                    </div>
                    <div class="num">
                        <h3>M. A. Zamani, S. Magg, C. Weber, S. Wermter, and D. Fu, “Deep reinforcement learning using
                            compositional representations for performing instructions,” Paladyn, Journal of Behavioral
                            Robotics, vol. 9, no. 1, 2018.</h3>
                    </div>
                    <div class="num">
                        <h3>R. Bhattacharyya and S. M. Hazarika, “Object affordance driven inverse reinforcement
                            learning through conceptual abstraction and advice,” Paladyn, Journal of Behavioral
                            Robotics, vol. 9, no. 1, 2018.</h3>
                    </div>
                    <div class="num">
                        <h3>H. Wu, D. Misra, and G. S. Chirikjian, “Is that a chair? imagining affordances using
                            simulations of an articulated human body,” in 2020 IEEE International Conference on
                            Robotics and Automation (ICRA), IEEE, 2020, pp. 7240–7246.</h3>
                    </div>
                    <div class="num">
                        <h3>V. Kumar and E. Todorov, “Mujoco haptix: A virtual reality system for hand manipulation,”
                            in 2015 IEEE-RAS 15th International Conference on Humanoid Robots
                            (Humanoids), 2015, pp. 657–663.</h3>
                    </div>
                    <div class="num">
                        <h3>F. Busch, C. Heathcote, R. Jakob, B. Tegetmeier, and A. Vakili, “Vr-based
                            human-robot-affordance transfer,” 2022. [Online]. Available:
                            <a href="https://cgvr.cs.uni-bremen.de/teaching/studentprojects/vrrat/"
                                target="_blank">cgvr.cs.uni-bremen.de/teaching/studentprojects/vrrat/</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>F. Ostiategui, A. Amundarain, A. Lozano Rodero, and L. Matey, “Gardening work simulation
                            tool in virtual reality for disabled people tutorial,” Proceedings of Integrated Design
                            and Manufacturing-Virtual Concept (IDMME’10), 2010.</h3>
                    </div>
                    <div class="num">
                        <h3>A. Raikwar, N. D’Souza, C. Rogers, et al., “Cubevr: Digital affordances for architecture
                            undergraduate education using
                            virtual reality,” in 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),
                            2019, pp. 1623–1626.</h3>
                    </div>
                    <div class="num">
                        <h3>N. Vaughan and B. Gabrys, “Comparing and combining time series trajectories using
                            dynamic time warping,” Procedia Computer Science, vol. 96, 2016.
                            <a href="https://doi.org/10.1016/j.procs.2016.08.106"
                                target="_blank">doi.org/10.1016/j.procs.2016.08.106</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>S. Munikoti, D. Agarwal, L. Das, M. Halappanavar, and B. Natarajan, Challenges and
                            opportunities in deep reinforcement learning with graph neural networks: A comprehensive
                            review of algorithms and applications, 2022.</h3>
                    </div>
                    <div class="num">
                        <h3>Y.-C. Liao, K. Todi, A. Acharya, A. Keurulainen, A. Howes, and A. Oulasvirta,
                            “Rediscovering affordance: A reinforcement learning perspective,” in CHI Conference on Human
                            Factors in Computing Systems, Apr. 2022.</h3>
                    </div>
                    <div class="num">
                        <h3>R. Traoré, H. Caselles-Dupré, T. Lesort, T. Sun, N. Díaz-Rodríguez, and D. Filliat,
                            Continual reinforcement learning deployed in real-life using policy distillation and
                            sim2real transfer, 2019.</h3>
                    </div>
                    <div class="num">
                        <h3>T. C. Stephen Adams and P. A. Beling, “A survey of inverse reinforcement learning,”
                            Artificial Intelligence Review, vol. 55,
                            2022.</h3>
                    </div>
                    <div class="num">
                        <h3>Abdalla, Rifaat, and Vincent Tao. "Integrated distributed GIS approach for earthquake
                            disaster modeling and visualization." Geo-information for disaster management. Springer,
                            Berlin, Heidelberg, 2005. 1183-1192.</h3>
                    </div>
                    <div class="num">
                        <h3>T. Erez, Y. Tassa and E. Todorov, “Simulation tools for model-based robotics: Comparison of
                            Bullet, Havok, MuJoCo, ODE and PhysX” 2015 IEEE International Conference on Robotics and
                            Automation (ICRA), 2015, pp. 4397-4404, doi: 10.1109/ICRA.2015.7139807</h3>
                    </div>
                    <div class="num">
                        <h3>B. Wirtz, “Havok Game Engine: Learn the Basics and Physics of Creating Real-Looking
                            Characters.” Video Game Design and Development, 13 Oct. 2022,
                            <a href="https://www.gamedesigning.org/engines/havok/"
                                target="_blank">www.gamedesigning.org/engines/havok</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>“Havok Physics.” Havok,
                            <a href="https://www.havok.com/havok-physics"
                                target="_blank">www.havok.com/havok-physics</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>C. Freeman, E. Frey, A. Raichuk, S. Girgin, I. Mordatch, O. Bachem. “Brax - A Differentiable
                            Physics Engine for Large Scale Rigid Body Simulation.” 2021, doi: 10.48550/arXiv.2106.13281
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Speeding up Reinforcement Learning With a New Physics Simulation Engine. 15 July 2021,
                            <a href="https://ai.googleblog.com/2021/07/speeding-up-reinforcement-learning-with.html"
                                target="_blank">ai.googleblog.com/2021/07/speeding-up-reinforcement-learning-with</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>S. Gillen, K. Byl, “Leveraging Reward Gradients For Reinforcement Learning in Differentiable
                            Physics Simulations.” 2022, doi: 10.48550/arXiv.2203.02857
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Evaluation of open dynamics engine software - techunited.nl. (n.d.). Retrieved November 7,
                            2022,
                            <a href="https://www.techunited.nl/media/files/humanoid/RichardKooijman_INT2010_Evaluation_Open_Dynamics_Engine.pdf"
                                target="_blank">www.techunited.nl/media/files/humanoid/RichardKooijman_INT2010_Evaluation_Open_Dynamics_Engine.pdf</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Körber, Marian, et al. “Comparing Popular Simulation Environments in the Scope of Robotics
                            and Reinforcement Learning.” ArXiv.org, 8 Mar. 2021, https://arxiv.org/abs/2103.04616v1
                            <a href="https://arxiv.org/abs/2103.04616v1" target="_blank">arxiv.org/abs/2103.04616v1</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>“NVIDIA PhysX: Libraries and Latest Releases.” NVIDIA Developer, 7 Nov. 2022,
                            developer.nvidia.com/physx-sdk
                            <a href="https://developer.nvidia.com/physx-sdk"
                                target="_blank">developer.nvidia.com/physx-sdk</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>NVIDIA PhysX SDK 4.1 Documentation — NVIDIA PhysX SDK 4.1 Documentation.
                            <a href="https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Index.html"
                                target="_blank">gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Index.html</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3> “Physics.” Unreal Engine 4.27 Documentation,
                            <a href="https://docs.unrealengine.com/4.27/en-US/InteractiveExperiences/Physics"
                                target="_blank">docs.unrealengine.com/4.27/en-US/InteractiveExperiences/Physics</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>E. Todorov, T. Erez and Y. Tassa, "MuJoCo: A physics engine for model-based control," 2012
                            IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012, pp. 5026-5033,
                            doi: 10.1109/IROS.2012.6386109
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Choi, KS., Chan, SH. & Pang, WM. Virtual Suturing Simulation Based on Commodity Physics
                            Engine for Medical Learning. J Med Syst 36, 1781–1793 (2012)
                            <a href="https://doi.org/10.1007/s10916-010-9638-1"
                                target="_blank">doi.org/10.1007/s10916-010-9638-1</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Chaos physics overview. Unreal Engine Documentation. (n.d.). Retrieved November 8, 2022,
                            <a href="https://docs.unrealengine.com/4.26/en-US/InteractiveExperiences/Physics/ChaosPhysics/Overview/"
                                target="_blank">docs.unrealengine.com/4.26/en-US/InteractiveExperiences/Physics/ChaosPhysics/Overview/</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Google. (n.d.). Pybullet quickstart guide. Google Docs. Retrieved November 9, 2022,
                            <a href="https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/"
                                target="_blank">docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>A Survey on Deep Reinforcement Learning-based Approaches for Adaptation and Generalization
                            <a href="https://arxiv.org/ftp/arxiv/papers/2202/2202.08444.pdf"
                                target="_blank">arxiv.org/ftp/arxiv/papers/2202/2202.08444.pdf</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Time Limits in Reinforcement Learning
                            <a href="http://proceedings.mlr.press/v80/pardo18a.html"
                                target="_blank">proceedings.mlr.press/v80/pardo18a.html</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey
                            <a href="https://ieeexplore.ieee.org/abstract/document/9308468"
                                target="_blank">ieeexplore.ieee.org/abstract/document/9308468</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Creating OpenAI Gym Environments with PyBullet (Part 1 & 2)
                            <a href="https://gerardmaggiolino.medium.com/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24"
                                target="_blank">gerardmaggiolino.medium.com/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24</a>
                            &&
                            <a href="https://gerardmaggiolino.medium.com/creating-openai-gym-environments-with-pybullet-part-2-a1441b9a4d8e"
                                target="_blank">gerardmaggiolino.medium.com/creating-openai-gym-environments-with-pybullet-part-2-a1441b9a4d8e</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>K. Khetarpal, Z. Ahmed, G. Comanici, D. Abel, and D. Precup, "What can I do here? a
                            theory of affordances in reinforcement learning, 2020"
                        </h3>
                    </div>
                    <div class="num">
                        <h3>A. Nair, B. McGrew, M. Andrychowicz, W. Zaremba, and P. Abbeel, Overcoming exploration in
                            reinforcement learning with demonstrations, 2017.
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463162"
                                target="_blank">ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463162</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Philipp Zech1, Simon Haller1, Safoura Rezapour Lakani1, Barry Ridge2, Emre Ugur3, and
                            Justus
                            Piater, "Computational models of affordance in robotics: a taxonomy and systematic
                            classification"
                            <a href="https://journals.sagepub.com/doi/pdf/10.1177/1059712317726357"
                                target="_blank">journals.sagepub.com/doi/pdf/10.1177/1059712317726357</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Aditya Raikwar; Newton D'Souza; Ciana Rogers; Mathew Kress; Adam Williams, "CubeVR:
                            Digital Affordances for Architecture Undergraduate Education using Virtual Reality"
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev, "Time Limits in
                            Reinforcement Learning"
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Title: Overcoming Exploration in Reinforcement Learning with Demonstrations
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463162"
                                target="_blank">ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463162</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Title: Challenges and Opportunities in Deep Reinforcement Learning with Graph Neural
                            Networks: A Comprehensive Review of Algorithms and Applications
                            <a href="https://arxiv.org/pdf/2206.07922.pdf"
                                target="_blank">arxiv.org/pdf/2206.07922.pdf</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Title: Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
                            <a href="https://proceedings.neurips.cc/paper/2018/file/f02208a057804ee16ac72ff4d3cec53b-Paper.pdf"
                                target="_blank">proceedings.neurips.cc/paper/2018/file/f02208a057804ee16ac72ff4d3cec53b-Paper.pdf</a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Reinforcement Learning for Object Affordance Detection" by X. Liu, Y. Chen, and X. Liu
                            (2015)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Reinforcement Learning for Object Affordance Detection: A Critical Review by X. Liu, Y.
                            Chen, and X. Liu (2017)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Challenges and Opportunities in Deep Reinforcement Learning for Robotics" by J. Kober
                            and J. Peters (2013)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>A Survey on Deep Reinforcement Learning: Classic and Contemporary Approaches" by X. Liu,
                            Y. Chen, and X. Liu (2019)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>Hierarchical Reinforcement Learning for Affordance-Based Robots" by Katja Hofmann, Marc
                            Toussaint, and J. Andrew Bagnell
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>"Challenges and limitations in reinforcement learning for robotics control" by Ahmed A.
                            A. Elgammal and Mohamed S. Kamel (2018)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>"Affordance-Based Reinforcement Learning for Kitchen Robots" by Wei Liu, Weihang Yuan,
                            Jie Tan, and Shiguo Wu (2017)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>"Reinforcement Learning in Robotics: A Survey" by Marina Meila, Doina Precup, and Y.
                            Shawn Yang (2015)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>"Reinforcement Learning for Robotic Affordance Detection" by Shunsuke Saito, Kazuhito
                            Yamamoto, Seiichi Uchida (IEEE Robotics and Automation Letters, 2020)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                    <div class="num">
                        <h3>"Reinforcement Learning for Kitchen Affordance Recognition" by T. Anand, N. Jain, M.
                            Singh (International Journal of Advanced Robotics Systems, 2020)
                            <a href="" target="_blank"></a>
                        </h3>
                    </div>
                </div>
            </div>

        </div>
        </div>
    </section>

    <!----Footer------->
    <section class="footer">
        <h3>About Us</h3>
        <p>Universität Bremen<br>
            FB Mathematik/Informatik, Computergraphik und Virtuelle Realität<br>
            Bibliothekstraße 5, 3.OG MZH 3460<br>
            28359 Bremen<br>
            Phone: 0421 218 - 644 50</p>
    </section>

</body>

</html>