<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CreaBots | Approach</title>
    <link rel="stylesheet" href="style.css">
    <style>
        .container {
            /* Flex */
            display: flex;
            justify-content: center;
            align-items: center;
        }

        @media (max-width: 1024px) {
            .container {
                display: none;

            }
        }

        /* Figure */
        .figure:nth-of-type(2) {
            margin-left: 35px;
            margin-top: 70px;
        }

        /* Path */
        .figure__path {
            /* Flex */
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .figure__pathStart {
            width: 22px;
            height: 22px;
            border: solid 4px var(--color1);
            outline: solid 3.5px;
            border-radius: 50%;
            position: relative;
        }

        .figure__pathPoint {
            background-color: var(--color10);
            width: 9px;
            height: 9px;
            margin-top: 16px;
            border-radius: 50%;
        }

        .figure__pathPoint:last-of-type {
            margin-bottom: 16px;
        }

        .figure__path:last-of-type .figure__pathPoint {
            display: none;
        }

        /* Product */
        .figure__product {
            width: 350px;
            height: 150px;
            padding: 0 20px;
            border-radius: 1000px;

            /* Position */
            position: absolute;
            right: 50px;
            top: 50%;
            transform: translateY(-50%);

            /* Flex */
            display: flex;
            justify-content: space-evenly;
            align-items: center;
        }

        .figure__product::before {
            width: 0;
            height: 0;
            border: solid 15px;
            border-color: transparent transparent transparent var(--color2);

            content: '';
            position: absolute;
            right: calc(-2 * 15px + 2px);
            top: 50%;
            transform: translateY(-50%);
        }

        .figure__path:nth-of-type(2) .figure__product::before {
            border-color: transparent transparent transparent var(--color3);
        }

        .figure__path:nth-of-type(3) .figure__product::before {
            border-color: transparent transparent transparent var(--color4);
        }

        /* Product - Right */
        .figure__product--right {
            left: 50px;
            flex-direction: row-reverse;
        }

        .figure__product--right::before {
            border-color: transparent var(--color5) transparent transparent;
            left: calc(-2 * 15px + 2px);
        }

        .figure__path:nth-of-type(2) .figure__product--right::before {
            border-color: transparent var(--color6) transparent transparent;
        }

        .figure__path:nth-of-type(3) .figure__product--right::before {
            border-color: transparent var(--color7) transparent transparent;
        }

        .figure__productContent {
            padding: 10px 0;

            /* Flex */
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .figure__productName {
            color: var(--color8);
            margin-bottom: 5px;
            font-size: 22px;
            font-weight: 500;
        }

        .figure__productDesc {
            color: var(--color8);
            max-width: 140px;
            font-size: 10px;
            font-weight: 400;
        }

        .figure__productIconBox {
            background-color: var(--color9);
            width: 95px;
            height: 95px;
            padding: 15px;
            border-radius: 50%;
            box-shadow: rgba(50, 50, 93, 0.25) 10px 13px 27px -5px, rgba(0, 0, 0, 0.3) 10px 8px 16px -8px;

            /* Flex */
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .figure__product--right .figure__productIconBox {
            box-shadow: rgba(50, 50, 93, 0.25) -10px 13px 27px -5px, rgba(0, 0, 0, 0.3) -10px 8px 16px -8px;
        }

        .figure__productIcon {
            width: 60px;
            height: 60px;
        }

        .collapsible {
            background-color: #777;
            color: white;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 15px;
        }

        .active,
        .collapsible:hover {
            background-color: #454545;
        }

        .collapsible:after {
            content: '\002B';
            color: white;
            font-weight: bold;
            float: right;
            margin-left: 5px;
        }

        .active:after {
            content: "\2212";
        }

        .content {
            padding: 0 18px;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.2s ease-out;
            background-color: #f1f1f1;
            text-align: left;
        }
    </style>
</head>

<body>
    <nav class="navbar" style="background-image: url('images/bg.gif');">
        <a href="index.html"><img class="logo" src="images/logo.png" alt="Creabots Logo" /></a>
        <div class="nav-links" id="navLinks">
            <i class="fa fa-times" onclick="hideMenu()" aria-hidden="true"></i>
            <ul>
                <li><a href="index.html">HOME</a></li>
                <li><a href="index.html#demo">DEMO</a></li>
                <li><a href="media.html">MEDIA</a></li>
                <li><a href="model.html">MODEL</a></li>
                <li><a href="index.html#team">TEAM</a></li>
                <li><a href="reference.html">REFERENCE</a></li>
            </ul>
        </div>

        <i class="fa fa-bars" onclick="showMenu()" aria-hidden="true"></i>
    </nav>

    <section class="approach">
        <h1 id="approach">Our Approach</h1>

        <br><br>

        <button class="collapsible">Taxonomy</button>
        <div class="content">
            <p>Based on our observations, we propose the taxonomy for components, which are required to describe the
                physical motions to fulfil an affordance. An affordance can have one or multiple of these
                components, which may be fulfilled at the same time or sequentially. While not all classes of components
                could be included in the experiments, we evaluated the taxonomy by referencing a list of over hundred
                affordances and testing whether we were able to describe the affordances based on this taxonomy. We
                did not find any exceptions to the taxonomy, therefore, we consider it to be sufficiently complete for
                future use, though further verification is recommended.
            </p>
        </div>
        <button class="collapsible">Reinforcement Learning (OpenAI)</button>
        <div class="content">
            <p>Due to the limitless amount of affordances, it would be unfeasible to define and train every affordance
                individually.
                Instead, we tried to keep the reward functions as general as possible, only using the successful
                end-state of the affordance (i.e. the pot is covered or the card is inside the box) to simulate a
                generic approach to affordance learning.

                There were a few more affordances taken into consideration for the experiments, however, most were
                dropped due to limited resources and time limitations on implementation.
                These affordances include: Stirring Objects in a Pot, Cutting a String, Cutting a Fruit and Wrapping a
                Chain around a Horizontal Pole.
                The chain affordance proved to be quite troublesome, in particular, as the handling of the chain by the
                physics engine turned out to be rather unreliable in both MuJoCo and PyBullet.
                While the chain by itself could be handled somewhat sufficiently, as soon as the agent gained control
                over any part of the chain, the behaviour became unpredictable and the joint connection seemed to be
                ineffective.

                When comparing the two physics engines, MuJoCo had a lot of tunnelling between objects (i.e. the toast
                would simply drop through the pan).
                Using internal primitives instead of external objects solved these issues; although, in many cases, it
                came at the cost of precision.
                Furthermore, even small changes to mass seemed to have an unnaturally strong effect on the interaction
                between objects.
                While tunnelling could also be seen in PyBullet, it was only encountered at rather large simulation step
                sizes, which is expected.
                All-in-all, we found that PyBullet was a lot more stable and predictable, as well as more accessible
                thanks to more extensive documentation.
                Unfortunately, this stability came at the cost of speed, as the training took about 2-3 times as long
                when using PyBullet instead of MuJoCo.
                This resulted in PyBullet not making it into the final training of the agents, due to time limitations.
                Thus, all the results have been achieved under the use of MuJoCo.
            </p>
        </div>
        <button class="collapsible">3D Modelling</button>
        <div class="content">
            <p>More than thirty 3D models are designed to perform different affordances in Virtual Reality as well as
                Motion Tracking. They are created by the open source software, Blender.</p>
        </div>
        <button class="collapsible">Virtual Reality (VR)</button>
        <div class="content">
            <p>The virtual reality setup is rather simple as it involves mainly the recreation of the motion tracking
                scene in the Unreal Engine. We experimented with a VR headset, the HTC Vive Pro Eye with its native
                controllers.
                To ensure that the environments of virtual reality scenes and OptiTrack scenes properly relate to each
                other, the scene's dimensions were measured beforehand and applied to the virtual scene.
                Likewise, the objects were modelled after the measurements of their real world counterparts.
                One major issue with the involved objects is that most of them were non-convex, as this property is
                quite common with household objects.
                Unfortunately, the PhysX Engine can, just like MuJoCo and PyBullet, only handle convex objects.
                Since a pure convex hull would not be accurate enough for many of our objects, convex decomposition was
                necessary.
                At first, we tried the V-HACD algorithm which generated too many colliders, resulting in bad
                performance.
                As a solution, we had to decompose the objects manually in blender, which resulted in more uniform
                colliders, improving not only the performance, but also the collision detection in the process.
                Finally, it had to be ensured that the starting position of the involved objects were consistent with
                the OptiTrack setup, which was achieved by marking key positions in the OptiTrack setup with tape---so
                that they can easily be recreated.
                Only basic interaction for the used virtual reality headset and controllers need to be implemented and
                accurately calibrated, and as long as these steps are followed, both environments are comparative.
            </p>
        </div>
        <button class="collapsible">Motion Tracking (OptiTrack)</button>
        <div class="content">
            <p>OptiTrack Motive is a motion capture software developed by OptiTrack, which is used for capturing and
                analysing the movement of objects or people in 3D space.
                Motive uses advanced algorithms and image processing techniques to track and record the movement of
                reflective markers placed on the subject or object being tracked.
                When combined with Unreal Engine, it offers a solution to create virtual environments that can simulate
                real-life scenarios with high precision.

                For the experiments, we used OptiTrack Motive 2.0.1, which was operated using a combination of cameras
                including 13 Primex 13 and 4 Primex 41.
                The experiments were conducted on a computer system comprising an Intel i7-4790 processor with 4 cores
                clocked at 3.6 GHz, 32 GB of 3600 MHz DDR4 RAM, and a Nvidia Titan V 12 GB graphics card.
                The system was integrated with Unreal Engine 4.27.

                The initial step in utilising the OptiTrack system involves the precise setup of the tracking area by
                positioning the cameras in appropriate locations and calibrating them to ensure accurate tracking.

                This calibration process is critical to achieving reliable and reproducible tracking results.
            </p>
        </div>
        <button class="collapsible">Affordances</button>
        <div class="content">
            <p>The affordances are selected based on properties, which we estimated may pose challenges on the
                reinforcement learning, the physics engine, or the execution in virtual environments.
                Some of the selected affordances have properties that are challenging for reinforcement learning and are
                only tested in that context not in the virtual unreal environment.
                <br>
                Here is the list of affordances we used:
            <ul>
                <li>Covering a Pot</li>
                <li>Flipping Object in a Pan</li>
                <li>Pouring Liquids</li>
                <li>Insert card in mailbox</li>
                <li>Balancing objects on a tray</li>
                <li>Puzzle assembly</li>
            </ul>
            </p>
        </div>

        <br><br><br>

    </section>

    <!----Footer------->
    <section class="footer">
        <h3>About Us</h3>
        <p>Universität Bremen<br>
            FB Mathematik/Informatik, Computergraphik und Virtuelle Realität<br>
            Bibliothekstraße 5, 3.OG MZH 3460<br>
            28359 Bremen<br>
            Phone: 0421 218 - 644 50</p>
    </section>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function () {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.maxHeight) {
                    content.style.maxHeight = null;
                } else {
                    content.style.maxHeight = content.scrollHeight + "px";
                }
            });
        }
    </script>
</body>

</html>